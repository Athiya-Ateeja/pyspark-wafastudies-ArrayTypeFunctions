{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aa2b828-83ab-486d-a9bd-5f08903717b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+\n| id|  Name|          Skills|\n+---+------+----------------+\n|  1|Athiya|   [java, Azure]|\n|  2|  sana|[dotnet, python]|\n+---+------+----------------+\n\nroot\n |-- id: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- Skills: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'Athiya',['java','Azure']),\n",
    "        (2,'sana',['dotnet','python'])]\n",
    "schema = ['id','Name','Skills']\n",
    "df= spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74bd53a-6db6-440f-8307-acfd2e235982",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a1ab87-2bbc-4e8c-a9b4-e5a777cf7a28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n| id|  Name|Skills|\n+---+------+------+\n|  1|Athiya|  java|\n|  1|Athiya| Azure|\n|  2|  sana|dotnet|\n|  2|  sana|python|\n+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Skills',explode(col('Skills')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56cb062c-8c10-4164-99a2-b1df203af9bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------+\n| id|  name|       skills|\n+---+------+-------------+\n|  1|Athiya|   azure,java|\n|  2|  Sana|dotnet,python|\n+---+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [('1','Athiya','azure,java'),\n",
    "        (2,'Sana','dotnet,python')]\n",
    "schema = ['id','name','skills']\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c8563c5-fd4d-4f47-867e-16092f5d5bae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e199ab-be5e-45fa-b916-95ff01a7392c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------+----------------+\n| id|  name|       skills|     skillsArray|\n+---+------+-------------+----------------+\n|  1|Athiya|   azure,java|   [azure, java]|\n|  2|  Sana|dotnet,python|[dotnet, python]|\n+---+------+-------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('skillsArray',split(col('skills'),','))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f7ad24-8c55-4afd-9313-021dd37428ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+\n| id|  Name|pSkill| Sskill|\n+---+------+------+-------+\n|  1|Athiya|  java|    sql|\n|  2|  Sana|python|pyspark|\n+---+------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [('1','Athiya','java','sql'),\n",
    "        (2,'Sana','python','pyspark')]\n",
    "schema = ['id','Name','pSkill','Sskill']\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "240c3e2c-73de-4a22-8f76-857fb2df77df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39f1407-dd74-46f3-8d03-28286b9f193d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------+-----------------+\n| id|  Name|pSkill| Sskill|      SkillsArray|\n+---+------+------+-------+-----------------+\n|  1|Athiya|  java|    sql|      [java, sql]|\n|  2|  Sana|python|pyspark|[python, pyspark]|\n+---+------+------+-------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('SkillsArray',array(col('pSkill'),col('Sskill')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23152aaf-ec3f-42e8-9155-fc73059a51ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+\n| id|  Name|          Skills|\n+---+------+----------------+\n|  1|Athiya|   [java, Azure]|\n|  2|  sana|[dotnet, python]|\n+---+------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'Athiya',['java','Azure']),\n",
    "        (2,'sana',['dotnet','python'])]\n",
    "schema = ['id','Name','Skills']\n",
    "df= spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2315440b-95e9-4829-aaa6-1aae67590131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c48af5-b465-43f8-989c-78b3db337661",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"HasJavaSkill\",array_contains(col('Skills'),'java'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d92cfbdc-94a7-469e-9e90-7259ee97f346",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------------+\n| id|  Name|          Skills|HasJavaSkill|\n+---+------+----------------+------------+\n|  1|Athiya|   [java, Azure]|        true|\n|  2|  sana|[dotnet, python]|       false|\n+---+------+----------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a30c8d9c-1634-49e6-a6d8-97f17a371794",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ArrayTypeFunctions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
